{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "stone-backing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "legal-choir",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import bwsample as bws"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "associate-sponsorship",
   "metadata": {},
   "source": [
    "# Toy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "coated-fruit",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (\n",
    "    ([1, 0, 0, 2], ['A', 'B', 'C', 'D']),\n",
    "    ([1, 0, 0, 2], ['A', 'B', 'C', 'D']), \n",
    "    ([2, 0, 0, 1], ['A', 'B', 'C', 'D']), \n",
    "    ([0, 1, 2, 0], ['A', 'B', 'C', 'D']),\n",
    "    ([0, 1, 0, 2], ['A', 'B', 'C', 'D']),\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "data = (\n",
    "    ([1, 0, 0, 2], ['A', 'B', 'C', 'D']),\n",
    "    ([1, 0, 0, 2], ['A', 'B', 'C', 'D']), \n",
    "    ([2, 0, 0, 1], ['A', 'B', 'C', 'D']), \n",
    "    ([1, 2, 0, 0], ['D', 'E', 'F', 'A']),\n",
    "    ([0, 2, 1, 0], ['D', 'E', 'F', 'A']),\n",
    "    ([0, 0, 1, 2], ['D', 'E', 'F', 'A'])\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# Extract pair frequencies\n",
    "dok, dok_direct, _, _ = bws.extract_pairs_batch2(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "alone-biotechnology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 2 3 3]\n",
      " [3 0 2 4]\n",
      " [1 0 0 3]\n",
      " [1 1 2 0]]\n"
     ]
    }
   ],
   "source": [
    "# convert to sparse matrix\n",
    "cnt, _ = bws.to_scipy(dok)\n",
    "print(cnt.todense().astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "stunning-peeing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 2]\n",
      " [0 0 1 1]\n",
      " [0 0 0 0]\n",
      " [1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "cnt_direct, _ = bws.to_scipy(dok_direct)\n",
    "print(cnt_direct.todense().astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposed-disposal",
   "metadata": {},
   "source": [
    "# Orme's Scores\n",
    "[Orme (2009)](https://sawtoothsoftware.com/uploads/sawtoothsoftware/originals/f89a6537-1cae-4fb5-afad-9d325c2a3143.pdf) proposed to **count only the items that have been labelled as best and worst**, and compute the following score:\n",
    "\n",
    "$$\n",
    "s_i = \\frac{N_{i}^{(\\text{best})} - N_{i}^{(\\text{worst})}}{N_{i}^{(\\text{all})}}\n",
    "$$\n",
    "\n",
    "This approach has been adopted in papers like [Kiritchenko and Mohammad (2016](http://dx.doi.org/10.18653/v1/N16-1095), [2017](http://dx.doi.org/10.18653/v1/P17-2074)).\n",
    "Our main critique is that this approach ignores a great portion of extractable pairwise comparisons, what might motivates to sample a higher number of BWS sets for a given number of items.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "statistical-integral",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orme's scores:  [ 0.333  1.    -1.    -0.5  ] \n",
      "\n",
      "positions: [1, 0, 3, 2]\n",
      "ordered IDs: ['B', 'A', 'D', 'C']\n",
      "scores: [0.7215166276267619, 0.5853356924476254, 0.3978611857916892, 0.2952864554973954]\n"
     ]
    }
   ],
   "source": [
    "ranked, ordids, scores, metric = bws.rank(dok_direct, method='orme', calibration='platt')\n",
    "\n",
    "print(\"Orme's scores: \", metric.round(3), \"\\n\")\n",
    "print(f\"positions: {ranked}\") \n",
    "print(f\"ordered IDs: {ordids}\") \n",
    "print(f\"scores: {scores}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpha-breast",
   "metadata": {},
   "source": [
    "# Simple Ratios\n",
    "Ranks and scores based on *simple ratios* are computed as follows:\n",
    "\n",
    "1. Compute all ratios $\\mu_{ij} = \\frac{N_{ij}}{N_{ij} + N_{ji}} \\; \\forall i,j$\n",
    "2. Compute the row sums $s_i = \\sum_j \\mu_{ij}$\n",
    "3. Calibrate the values $s_i$ by Platt-Scaling as scores\n",
    "\n",
    "Further notes: The *simple ratio* approach ignores the sample sizes $N_{ij} + N_{ji}$\n",
    "across different pairs $(i,j)$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "coordinated-batman",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.   0.4  0.75 0.75]\n",
      " [0.6  0.   1.   0.8 ]\n",
      " [0.25 0.   0.   0.6 ]\n",
      " [0.25 0.2  0.4  0.  ]] \n",
      "\n",
      "positions: [1, 0, 2, 3]\n",
      "ordered IDs: ['B', 'A', 'C', 'D']\n",
      "scores: [0.5309053173967123, 0.5137516046973882, 0.47767157940158145, 0.47767157940158145]\n"
     ]
    }
   ],
   "source": [
    "ranked, ordids, scores, ratios = bws.rank(dok, method='ratio', avg='exist', calibration='platt')\n",
    "\n",
    "print(ratios.todense().round(3), \"\\n\")\n",
    "print(f\"positions: {ranked}\") \n",
    "print(f\"ordered IDs: {ordids}\") \n",
    "print(f\"scores: {scores}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "traditional-elite",
   "metadata": {},
   "source": [
    "# p-values based on Chi-Squared test\n",
    "The question which opposing frequency $N_{ij}$ or $N_{ji}$ is larger,\n",
    "can be treated as hypothesis test:\n",
    "\n",
    "$$\n",
    "\\mu = \\frac{N_{ij}}{N_{ij} + N_{ji}}\n",
    "\\quad , \\quad\n",
    "H_0: \\mu = 0.5\n",
    "\\quad , \\quad\n",
    "H_a: \\mu > 0.5\n",
    "$$\n",
    "\n",
    "The Pearson's $\\chi^2$-test is implemented as alternative to the binomal test with its discrete distribution.\n",
    "\n",
    "1. Compute *p-value based* metric $x_{ij}$. Using $1-p$ allows to store a sparse matrix as we expect many pairs $(i,j)$ having no user evaluation at all.\n",
    "$$\n",
    "x_{ij} = \n",
    "\\left \\{\n",
    "\\begin{aligned}\n",
    "& 1-p_{ij}, & \\text{if} \\, N_{ij} > N_{ji} \\\\\n",
    "& 0, & \\text{otherwise}\n",
    "\\end{aligned} \n",
    "\\right.\n",
    "\\quad\n",
    "\\forall i,j\n",
    "$$\n",
    "2. Sum each row $r_i = \\sum_j x_{ij}$ and divide it by the actual number of row elements $n_i$\n",
    "3. Calibrate the values $r_i/n_i$ by Platt-Scaling as scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pediatric-entry",
   "metadata": {},
   "source": [
    "Further notes: We basically want to run [binomal test](https://en.wikipedia.org/wiki/Binomial_test) for an coin tossing type of experiment. \n",
    "When $N_{ij} > N_{ji}$, the lower the p-value of the Pearson Chi-Squared test, the more significant is the rejection of H0.\n",
    "In other words, the higher $x_{ij}$, the more signification is the $N_{ij} > N_{ji}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "spectacular-belfast",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.    0.    0.683 0.683]\n",
      " [0.345 0.    0.843 0.82 ]\n",
      " [0.    0.    0.    0.345]\n",
      " [0.    0.    0.    0.   ]] \n",
      "\n",
      "positions: [1, 0, 2, 3]\n",
      "ordered IDs: ['B', 'A', 'C', 'D']\n",
      "scores: [0.5422497422485285, 0.5170970398066642, 0.47705924601529226, 0.46354837474491195]\n"
     ]
    }
   ],
   "source": [
    "ranked, ordids, scores, minuspvalue = bws.rank(dok, method='pvalue', avg='exist', calibration='platt')\n",
    "\n",
    "print(minuspvalue.todense().round(3), \"\\n\")\n",
    "print(f\"positions: {ranked}\") \n",
    "print(f\"ordered IDs: {ordids}\") \n",
    "print(f\"scores: {scores}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indoor-shock",
   "metadata": {},
   "source": [
    "### Notes\n",
    "Why should we care about the size of $N$?\n",
    "A small gap between $N_{ij}=1$ vs $N_{ji}=2$ might be interpretated big ratio gap $1/3$ vs $2/3$.\n",
    "However, when collecting more data it might turn out $N_{ij}=1000$ vs $N_{ji}=1001$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "therapeutic-methodology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value=0.564 | Nij=1 vs Nji=2\n",
      "p-value=0.827 | Nij=10 vs Nji=11\n",
      "p-value=0.944 | Nij=100 vs Nji=101\n",
      "p-value=0.982 | Nij=1000 vs Nji=1001\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats\n",
    "\n",
    "for f1 in (1, 10, 100, 1000):\n",
    "    f2 = f1 + 1\n",
    "    fe = (f1 + f2) / 2\n",
    "    _, pval = scipy.stats.chisquare(f_obs=[f1, f2], f_exp=[fe, fe], ddof=0)\n",
    "    print(f\"p-value={pval:5.3f} | Nij={f1} vs Nji={f2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "black-poultry",
   "metadata": {},
   "source": [
    "# Eigenvector as scores\n",
    "The idea is to solve pairwise comparison matrix as Eigenvalue-problem whereas the eigenvector can be interpreted as the items' scores [(Saaty, 2003)](http://dx.doi.org/10.1016/S0377-2217(02)00227-8) .\n",
    "\n",
    "1. Create a reciprocal pairwise comparison matrix $A=(a_{ij})$ with \n",
    "$$\n",
    "a_{ij} = \n",
    "\\left \\{\n",
    "\\begin{aligned}\n",
    "& N_{ij} / N_{ji}, & \\text{if} \\, N_{ji} > 0 \\\\\n",
    "& 0, & \\text{otherwise}\n",
    "\\end{aligned} \n",
    "\\right.\n",
    "\\quad\n",
    "\\forall i,j\n",
    "$$\n",
    "2. Solve the Eigenvalue-problem $A x = m x$ with $m$ the eigenvalue and $x=[x_1, x_2, ...,x_N]$ the eigenvector,\n",
    "3. Calibrate the eigenvector $x$ with Platt-Scaling as scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "illegal-desert",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvector: [[0.65510149 0.69815317 0.20364194 0.2048271 ]]\n",
      "positions: [1, 0, 3, 2]\n",
      "ordered IDs: ['B', 'A', 'D', 'C']\n",
      "scores: [0.5287918016485688, 0.5239904013016199, 0.4736750157953159, 0.47354283833863525]\n"
     ]
    }
   ],
   "source": [
    "ranked, ordids, scores, (eigval, eigvec) = bws.rank(dok, method='eigen', calibration='platt')\n",
    "\n",
    "print(f\"eigenvector: {np.abs(np.real(eigvec.reshape(1,-1)))}\")\n",
    "\n",
    "print(f\"positions: {ranked}\") \n",
    "print(f\"ordered IDs: {ordids}\") \n",
    "print(f\"scores: {scores}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confirmed-boundary",
   "metadata": {},
   "source": [
    "# Bradley-Terry-Luce (BTL) Model\n",
    "Given $M$ the number of items, and each item has a parameters $\\gamma_i \\in \\{x\\in\\mathbb{R} | 1 \\geq x \\geq 0 \\}$,\n",
    "the Bradley–Terry (1952) probability model is\n",
    "\n",
    "$$\n",
    "\\Pr(\\text{item}_i > \\text{item}_j) = \\frac{\\gamma_i}{\\gamma_i + \\gamma_j}\n",
    "$$\n",
    "\n",
    "Given the observed counts or frequencies $N_{ij}$.\n",
    "According to [Hunter (2004, p.386-387)](http://dx.doi.org/10.1214/aos/1079120141)\n",
    "we can maximize the log-likilood \n",
    "\n",
    "$$\n",
    "\\max_{\\gamma_1, ..., \\gamma_M} \\quad \\sum_{i=1}^M \\sum_{j=1}^M \n",
    "N_{ij} \\left[\\ln(\\gamma_i) - \\ln(\\gamma_i + \\gamma_j) \\right]\n",
    "$$\n",
    "\n",
    "by updating in $k=1,2,...,K$ iteration steps\n",
    "\n",
    "$$\n",
    "\\gamma_i^{(k+1)} =  \\text{norm}\\left[ \\sum_{j=1}^M N_{ij} \\cdot \\left( \\sum_{j\\neq i} \\frac{N_{ij} + N_{ji}}{\\gamma_i^{(k)} + \\gamma_j^{(k)}} \\right)^{-1} \\right]\n",
    "$$\n",
    "\n",
    "with \n",
    "\n",
    "$$\n",
    "\\text{norm}(x_1, ..., x_M) = \\frac{x_i}{\\sum_{j=1}^M x_j}\n",
    "$$ \n",
    "\n",
    "to ensure $\\sum_{i=1}^M \\gamma_i^{(k+1)} = 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "arctic-compact",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimated MLE parameters: [0.27382345 0.34467813 0.25312112 0.1283773 ] \n",
      "\n",
      "positions: [1, 0, 2, 3]\n",
      "ordered IDs: ['B', 'A', 'C', 'D']\n",
      "scores: [1.0, 0.6724252569161807, 0.5767144347046128, 0.0]\n"
     ]
    }
   ],
   "source": [
    "ranked, ordids, scores, x = bws.rank(dok, method='btl', max_iter=100, tol=1e-8, prefit=True, calibration='minmax')\n",
    "\n",
    "print(f\"estimated MLE parameters: {x}\", \"\\n\") \n",
    "\n",
    "print(f\"positions: {ranked}\") \n",
    "print(f\"ordered IDs: {ordids}\") \n",
    "print(f\"scores: {scores}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brief-chorus",
   "metadata": {},
   "source": [
    "# Estimate and simulate a transition matrix\n",
    "Approach:\n",
    "\n",
    "1. Compute a transition probability matrix $\\Pr(k|j)$ of items $e$ being evaluated $\\text{item}_k > \\text{item}_j$\n",
    "2. Simulate the transition matrix\n",
    "    - The initial items are equally distributed with item probability $\\pi_j = 1/N \\; \\forall j$.\n",
    "    - Predict the probability of the items $\\pi_k = \\pi_j \\cdot \\Pr(k|j)$\n",
    "3. Calibrate the item probabilities $\\pi_k$ to scores. Run Platt-Scaling against binary labels $y=1_{\\pi_k>1/N}$\n",
    "\n",
    "Settings:\n",
    "\n",
    "- It is possible to skip the calibration step (3) by `calibration=None`.\n",
    "- Isotonic Regression `calibration='isotonic'` should be used for large numbers items $N>1000$.\n",
    "- `n_rounds` is number of simulation steps to compute $\\pi_k$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "appointed-scope",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.488 0.278 0.098 0.136]\n",
      " [0.299 0.484 0.05  0.167]\n",
      " [0.237 0.197 0.409 0.156]\n",
      " [0.207 0.224 0.134 0.435]]\n",
      "predicted probabilities: [0.33187441 0.31953262 0.13568109 0.21291187] \n",
      "\n",
      "positions: [0, 1, 3, 2]\n",
      "ordered IDs: ['A', 'B', 'D', 'C']\n",
      "scores: [1.0, 0.9370937652080424, 0.39364634516069397, 0.0]\n"
     ]
    }
   ],
   "source": [
    "ranked, ordids, scores, (x, transmat) = bws.rank(dok, method='transition', n_rounds=3, calibration='minmax')\n",
    "\n",
    "print(transmat.todense().round(3))\n",
    "print(f\"predicted probabilities: {x}\", \"\\n\") \n",
    "\n",
    "print(f\"positions: {ranked}\") \n",
    "print(f\"ordered IDs: {ordids}\") \n",
    "print(f\"scores: {scores}\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
