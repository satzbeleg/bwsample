{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "permanent-herald",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "regulated-brazil",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import bwsample as bws"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interior-kidney",
   "metadata": {},
   "source": [
    "# Toy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "hearing-shelter",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (\n",
    "    ([1, 0, 0, 2], ['A', 'B', 'C', 'D']),\n",
    "    ([1, 0, 0, 2], ['A', 'B', 'C', 'D']), \n",
    "    ([2, 0, 0, 1], ['A', 'B', 'C', 'D']), \n",
    "    ([0, 1, 2, 0], ['A', 'B', 'C', 'D']),\n",
    "    ([0, 1, 0, 2], ['A', 'B', 'C', 'D']),\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "data = (\n",
    "    ([1, 0, 0, 2], ['A', 'B', 'C', 'D']),\n",
    "    ([1, 0, 0, 2], ['A', 'B', 'C', 'D']), \n",
    "    ([2, 0, 0, 1], ['A', 'B', 'C', 'D']), \n",
    "    ([1, 2, 0, 0], ['D', 'E', 'F', 'A']),\n",
    "    ([0, 2, 1, 0], ['D', 'E', 'F', 'A']),\n",
    "    ([0, 0, 1, 2], ['D', 'E', 'F', 'A'])\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# Extract pair frequencies\n",
    "dok, _, _, _ = bws.extract_pairs_batch2(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "decimal-fortune",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 2 3 3]\n",
      " [3 0 2 4]\n",
      " [1 0 0 3]\n",
      " [1 1 2 0]]\n"
     ]
    }
   ],
   "source": [
    "# convert to sparse matrix\n",
    "cnt, _ = bws.to_scipy(dok)\n",
    "print(cnt.todense().astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unable-burden",
   "metadata": {},
   "source": [
    "# Simple Ratios\n",
    "Ranks and scores based on *simple ratios* are computed as follows:\n",
    "\n",
    "1. Compute all ratios $\\mu_{ij} = \\frac{N_{ij}}{N_{ij} + N_{ji}} \\; \\forall i,j$\n",
    "2. Compute the row sums $s_i = \\sum_j \\mu_{ij}$\n",
    "3. Calibrate the values $s_i$ by Platt-Scaling as scores\n",
    "\n",
    "Further notes: The *simple ratio* approach ignores the sample sizes $N_{ij} + N_{ji}$\n",
    "across different pairs $(i,j)$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "american-bumper",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.   0.4  0.75 0.75]\n",
      " [0.6  0.   1.   0.8 ]\n",
      " [0.25 0.   0.   0.6 ]\n",
      " [0.25 0.2  0.4  0.  ]] \n",
      "\n",
      "positions: [1, 0, 2, 3]\n",
      "ordered IDs: ['B', 'A', 'C', 'D']\n",
      "scores: [0.5309053173967123, 0.5137516046973882, 0.47767157940158145, 0.47767157940158145]\n"
     ]
    }
   ],
   "source": [
    "ranked, ordids, scores, ratios = bws.rank(dok, method='ratio', avg='exist', calibration='platt')\n",
    "\n",
    "print(ratios.todense().round(3), \"\\n\")\n",
    "print(f\"positions: {ranked}\") \n",
    "print(f\"ordered IDs: {ordids}\") \n",
    "print(f\"scores: {scores}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latin-scope",
   "metadata": {},
   "source": [
    "# p-values based on Chi-Squared test\n",
    "The question which opposing frequency $N_{ij}$ or $N_{ji}$ is larger,\n",
    "can be treated as hypothesis test:\n",
    "\n",
    "$$\n",
    "\\mu = \\frac{N_{ij}}{N_{ij} + N_{ji}}\n",
    "\\quad , \\quad\n",
    "H_0: \\mu = 0.5\n",
    "\\quad , \\quad\n",
    "H_a: \\mu > 0.5\n",
    "$$\n",
    "\n",
    "The Pearson's $\\chi^2$-test is implemented as alternative to the binomal test with its discrete distribution.\n",
    "\n",
    "1. Compute *p-value based* metric $x_{ij}$. Using $1-p$ allows to store a sparse matrix as we expect many pairs $(i,j)$ having no user evaluation at all.\n",
    "$$\n",
    "x_{ij} = \n",
    "\\left \\{\n",
    "\\begin{aligned}\n",
    "& 1-p_{ij}, & \\text{if} \\, N_{ij} > N_{ji} \\\\\n",
    "& 0, & \\text{otherwise}\n",
    "\\end{aligned} \n",
    "\\right.\n",
    "\\quad\n",
    "\\forall i,j\n",
    "$$\n",
    "2. Sum each row $r_i = \\sum_j x_{ij}$ and divide it by the actual number of row elements $n_i$\n",
    "3. Calibrate the values $r_i/n_i$ by Platt-Scaling as scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sealed-editing",
   "metadata": {},
   "source": [
    "Further notes: We basically want to run [binomal test](https://en.wikipedia.org/wiki/Binomial_test) for an coin tossing type of experiment. \n",
    "When $N_{ij} > N_{ji}$, the lower the p-value of the Pearson Chi-Squared test, the more significant is the rejection of H0.\n",
    "In other words, the higher $x_{ij}$, the more signification is the $N_{ij} > N_{ji}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "compact-norway",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.    0.    0.683 0.683]\n",
      " [0.345 0.    0.843 0.82 ]\n",
      " [0.    0.    0.    0.345]\n",
      " [0.    0.    0.    0.   ]] \n",
      "\n",
      "positions: [1, 0, 2, 3]\n",
      "ordered IDs: ['B', 'A', 'C', 'D']\n",
      "scores: [0.5422497422485285, 0.5170970398066642, 0.47705924601529226, 0.46354837474491195]\n"
     ]
    }
   ],
   "source": [
    "ranked, ordids, scores, minuspvalue = bws.rank(dok, method='pvalue', avg='exist', calibration='platt')\n",
    "\n",
    "print(minuspvalue.todense().round(3), \"\\n\")\n",
    "print(f\"positions: {ranked}\") \n",
    "print(f\"ordered IDs: {ordids}\") \n",
    "print(f\"scores: {scores}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ideal-teaching",
   "metadata": {},
   "source": [
    "### Notes\n",
    "Why should we care about the size of $N$?\n",
    "A small gap between $N_{ij}=1$ vs $N_{ji}=2$ might be interpretated big ratio gap $1/3$ vs $2/3$.\n",
    "However, when collecting more data it might turn out $N_{ij}=1000$ vs $N_{ji}=1001$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sacred-storm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value=0.564 | Nij=1 vs Nji=2\n",
      "p-value=0.827 | Nij=10 vs Nji=11\n",
      "p-value=0.944 | Nij=100 vs Nji=101\n",
      "p-value=0.982 | Nij=1000 vs Nji=1001\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats\n",
    "\n",
    "for f1 in (1, 10, 100, 1000):\n",
    "    f2 = f1 + 1\n",
    "    fe = (f1 + f2) / 2\n",
    "    _, pval = scipy.stats.chisquare(f_obs=[f1, f2], f_exp=[fe, fe], ddof=0)\n",
    "    print(f\"p-value={pval:5.3f} | Nij={f1} vs Nji={f2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geological-infrastructure",
   "metadata": {},
   "source": [
    "# Eigenvector as scores\n",
    "The idea is to solve pairwise comparison matrix as Eigenvalue-problem whereas the eigenvector can be interpreted as the items' scores [(Saaty, 2003)](http://dx.doi.org/10.1016/S0377-2217(02)00227-8) .\n",
    "\n",
    "1. Create a reciprocal pairwise comparison matrix $A=(a_{ij})$ with \n",
    "$$\n",
    "a_{ij} = \n",
    "\\left \\{\n",
    "\\begin{aligned}\n",
    "& N_{ij} / N_{ji}, & \\text{if} \\, N_{ji} > 0 \\\\\n",
    "& 0, & \\text{otherwise}\n",
    "\\end{aligned} \n",
    "\\right.\n",
    "\\quad\n",
    "\\forall i,j\n",
    "$$\n",
    "2. Solve the Eigenvalue-problem $A x = m x$ with $m$ the eigenvalue and $x=[x_1, x_2, ...,x_N]$ the eigenvector,\n",
    "3. Calibrate the eigenvector $x$ with Platt-Scaling as scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "secret-phoenix",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvector: [[0.65510149 0.69815317 0.20364194 0.2048271 ]]\n",
      "positions: [1, 0, 3, 2]\n",
      "ordered IDs: ['B', 'A', 'D', 'C']\n",
      "scores: [0.6981531725668787, 0.6551014935159343, 0.20482709915914155, 0.2036419413530658]\n"
     ]
    }
   ],
   "source": [
    "ranked, ordids, scores, (eigval, eigvec) = bws.rank(dok, method='eigen', calibration=None)\n",
    "\n",
    "print(f\"eigenvector: {np.abs(np.real(eigvec.reshape(1,-1)))}\")\n",
    "\n",
    "print(f\"positions: {ranked}\") \n",
    "print(f\"ordered IDs: {ordids}\") \n",
    "print(f\"scores: {scores}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nominated-greenhouse",
   "metadata": {},
   "source": [
    "# Estimate and simulate a transition matrix\n",
    "Approach:\n",
    "\n",
    "1. Compute a transition probability matrix $\\Pr(k|j)$ of items $e$ being evaluated $e_k > e_j$\n",
    "2. Simulate the transition matrix\n",
    "    - The initial items are equally distributed with item probability $\\pi_j = 1/N \\; \\forall j$.\n",
    "    - Predict the probability of the items $\\pi_k = \\pi_j \\cdot \\Pr(k|j)$\n",
    "3. Calibrate the item probabilities $\\pi_k$ to scores. Run Platt-Scaling against binary labels $y=1_{\\pi_k>1/N}$\n",
    "\n",
    "Settings:\n",
    "\n",
    "- It is possible to skip the calibration step (3) by `calibration=None`.\n",
    "- Isotonic Regression `calibration='isotonic'` should be used for large numbers items $N>1000$.\n",
    "- `n_rounds` is number of simulation steps to compute $\\pi_k$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "piano-realtor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.488 0.278 0.098 0.136]\n",
      " [0.299 0.484 0.05  0.167]\n",
      " [0.237 0.197 0.409 0.156]\n",
      " [0.207 0.224 0.134 0.435]]\n",
      "predicted probabilities: [0.33187441 0.31953262 0.13568109 0.21291187] \n",
      "\n",
      "positions: [0, 1, 3, 2]\n",
      "ordered IDs: ['A', 'B', 'D', 'C']\n",
      "scores: [0.5030788667074934, 0.5026147386196117, 0.49860502987470134, 0.4957006782793525]\n"
     ]
    }
   ],
   "source": [
    "ranked, ordids, scores, (x, transmat) = bws.rank(dok, method='transition', n_rounds=3, calibration='platt')\n",
    "\n",
    "print(transmat.todense().round(3))\n",
    "print(f\"predicted probabilities: {x}\", \"\\n\") \n",
    "\n",
    "print(f\"positions: {ranked}\") \n",
    "print(f\"ordered IDs: {ordids}\") \n",
    "print(f\"scores: {scores}\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
