import itertools  # to_scipy
import scipy.sparse  # to_scipy
import numpy as np  # to_scipy, calibrate
import sklearn.linear_model  # adjustscore
import sklearn.preprocessing  # adjustscore
import scipy.special  # adjustscore
from typing import Dict, Tuple, List, Optional
ItemID = str  # add_dok


def to_scipy(dok: Dict[Tuple[str, str], int], dtype=np.float64) -> (
        scipy.sparse.dok.dok_matrix, List[str]):
    """Convert dictionary with pairwise comparison frequencies
        in a scipy sparse matrix

    Parameters:
    -----------
    dok : Dict[Tuple[str, str], int]
        Count/Frequency data as Dictionary of Keys (DoK)

    dtype (Default: np.float64)
        Data type of the sparse matrix

    Returns:
    --------
    cnt : scipy.sparse.dok.dok_matrix
        Quadratic sparse matrix with frequency data

    indices : List[str]
        Identifiers, e.g. UUID4, of each row/column of the `cnt` matrix.

    Example:
    --------
        import bwsample as bws
        dok = {('A', 'D'): 3, ('A', 'B'): 2}
        cnt, indices = bws.to_scipy(dok)
    """
    idx = sorted(list(set(itertools.chain(*dok.keys()))))
    n_dim = len(idx)
    cnt = scipy.sparse.dok_matrix((n_dim, n_dim), dtype=dtype)
    for (i, j), v in dok.items():
        cnt[idx.index(i), idx.index(j)] = v
    return cnt, idx


def add_dok(a: Dict[Tuple[ItemID, ItemID], int],
            b: Dict[Tuple[ItemID, ItemID], int]
            ) -> Dict[Tuple[ItemID, ItemID], int]:
    """Add counts of two Dictionary of Keys (DOK) objects

    Parameters:
    -----------
    a, b : Dict[Tuple[ItemID, ItemID], int]
        Two Dictionary of Keys (DOK) objects which values
          are to be added.

    Returns:
    --------
    out : Dict[Tuple[ItemID, ItemID], int]
        A Dictionary of Keys (DOK) objects with the added values
          for each key.

    Example:
    --------
        import bwsample as bws
        a = {"key": 2, "misc": 3, ("id1", "id2"): 7}
        b = {"misc": 1}
        c = bws.add_dok(a, b)

    """
    if len(a) > len(b):
        # copy a to output
        out = a.copy()
        # add b to output
        for key, val in b.items():
            out[key] = val + out.get(key, 0)
    else:
        # copy b to output
        out = b.copy()
        # add a to output
        for key, val in a.items():
            out[key] = val + out.get(key, 0)
    # done
    return out


def minmax(arr: np.array) -> np.array:
    data = np.array(arr)
    xmin = data.min()
    xmax = data.max()
    return (data - xmin) / (xmax - xmin)


def adjustscore(scores: np.array,
                method: Optional[str] = 'quantile',
                n_quantiles: Optional[int] = 10000,
                labels: Optional[np.array] = None) -> np.array:
    """Wrapper function to adjust scores

    Parameters:
    -----------
    scores: np.array
        The scores generated by a model.

    method: str (Default: None)
        The calibration algorithm:
            - 'quantile' -- sklearn's quantile transform
            - 'sig3iqr' -- sigmoid 3x sklearn's robust scaler with (25%,75%)
            - 'platt' -- calibrate scores with the binary labels (Platt, 1999)
            - 'minmax' -- Min-Max scaling

    n_quantiles: Optional[int] = 10000
        Parameter for `method='quantile'`

    labels: Optional[np.array]
        For `method='platt'`. The binary labels that are supposed to be
          classified by the scores.

    Return:
    -------
    adjusted : np.array
        The adjusted scores

    References:
    -----------
    Platt, J., 1999. Probabilistic outputs for support vector machines and
        comparisons to regularized likelihood methods.
    """
    scores = np.array(scores)
    if labels:
        labels = np.array(labels)

    if method == 'quantile':
        return sklearn.preprocessing.quantile_transform(
            X=scores.reshape(-1, 1),
            n_quantiles=min(n_quantiles, len(scores)),
            output_distribution='uniform').reshape(-1)

    elif method == 'sig3iqr':
        adjusted = sklearn.preprocessing.robust_scale(
            X=scores, quantile_range=(25, 75))
        return scipy.special.expit(3 * adjusted).reshape(-1)

    elif method == 'platt':
        cls = sklearn.linear_model.LogisticRegression()
        cls.fit(X=scores.reshape(-1, 1), y=labels)
        return cls.predict_proba(scores.reshape(-1, 1))[:, 1].reshape(-1)

    elif method == 'minmax':
        return minmax(scores)

    else:
        raise Exception(f"The method='{method}' is not implemented.")
